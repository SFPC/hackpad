<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en">
<head>
<meta http-equiv="Content-type" content="text/html; charset=utf-8" />
<meta http-equiv="Content-Language" content="en-us" />
<meta name="version" content="3759"/>
<style>body {font-family:Helvetica}ul.comment{list-style-image:url('https://hackpad.com/static/img/comment.png');} ul.task{list-style-image:url('https://hackpad.com/static/img/unchecked.png');}ul.taskdone{list-style-image:url('https://hackpad.com/static/img/checked.png');} </style><title>/3668$C0P9I94UP3r</title>
</head>
<body><h1>Alexander Porter &rsquo;Project Stack&rsquo;</h1><p><b>Intentions for SFPC</b></p><ul style="list-style: none;"><li><b>Develop artistic ideas in relation to:&nbsp;</b><ul style="list-style: none;"><li>The current state of cameras &amp; image taking.&nbsp;</li>
<li>Develop a framework for categorizing/understanding &amp; communicating about<ul style="list-style: none;"><li>images made by humans for humans</li>
<li>images made by humans for machines</li>
<li>images made by machines for humans</li>
<li>images made by machines for machines</li></ul style="list-style: none;">
</li>
<li>The implications of computational portraiture</li></ul style="list-style: none;">
</li>
<li><br/></li>
<li><b>Learn granular skills to enable specific things:</b></li><ul class="task"><li>Scripting/controlling my camera&nbsp;</li><ul style="list-style: none;"><li>Scripting Magic Lantern to do focus stepping for EDF etc.&nbsp;</li>
<li>Canon SDK via oF/Processing?<ul style="list-style: none;"><li>I know Canon SDK is notoriously finicky &amp; weird. Alternatives?&nbsp;</li></ul>
</ul>
</ul>
<ul class="taskdone"><li>Have facility with programming enough to use tools &amp; libraries in oF &amp; processing with facility and start creating own tools/programs.&nbsp;</li></ul>
<ul class="task"><li>Learn enough about programming &amp; scripting to automate tedious tasks in CG, photography, photogrammetry, 3D scanning etc.</li>
<li>Have enough information to be able to sketch in the browser. Load OBJ&rsquo;s, basic scenes etc.</li></ul>
<ul style="list-style: none;"><li><br/></li></ul style="list-style: none;">
</li>
<li><b>Pie-in-the-sky technical wishes:</b><ul style="list-style: none;"><li>Develop/adapt tools to do:&nbsp;<ul style="list-style: none;"><li>Coded aperture photography<ul style="list-style: none;"><li><a href="http://groups.csail.mit.edu/graphics/CodedAperture/"></a>http://groups.csail.mit.edu/graphics/CodedAperture/</li></ul style="list-style: none;">
</li>
<li>Synthetic aperture</li>
<li>A project exploiting Helmholtz reciprocity [the notion of a projector as inverse-camera &amp; visa versa]&nbsp;&nbsp;</li>
<li>Lightfield/plenoptic-type refocusing etc from camera arrays.&nbsp;</li>
<li>Represent LIDAR or other pointcloud datasets programmatically.&nbsp;</li></ul style="list-style: none;">
</li>
<li>&nbsp;</li></ul style="list-style: none;">
</li>
<li><b>Understand the rudiments of:</b></li><ul class="taskdone"><li>Programming &amp; computation.</li>
<li>What happens in a digital camera from capture to image compression.</li></ul>
<ul class="task"><li>Learn the basics of graphics</li></ul>
</ul>

<p><b>Projects that (whimsically) came to mind prior to the course:</b></p><ul><li>Create landscape/reliefs by using photo forensic software and mapping ELA (or other alterations) to elevation. Apply to various images, sets and make various &rsquo;landscapes of manipulation.&rsquo;</li><ul style="list-style: none;"><li><a href="http://www.getghiro.org/"></a>http://www.getghiro.org/&nbsp;</li></ul>
</li>
<li>Create a camera that retrieves the image search result for the image you take, discards your image and presents the first search result in its place.</li>
<li>An image search video process – perform image search + crop to match for every frame of an image sequence.&nbsp;</li>
<li>Make sequences (CG or generative) that convey the physical reality of &rsquo;materials intensity&rsquo; &amp; material throughput in our lives. Translate data about C02 consumption, materials use, waste etc. and make animations to visualize them. Ie: calculate actual C02 used during the course of a year and animate it falling at human scale.</li>
<li>Attempt to illustrate the odd similes used to put things in scales we can understand. For example (made up): the number of water bottles used per month would fill the empire state building. Could VR or animation overcome cognitive biases that prevent us from comprehending &amp; comparing large numbers or minute risks?</li><ul style="list-style: none;"><li><a href="http://rationalwiki.org/wiki/List_of_cognitive_biases"></a>http://rationalwiki.org/wiki/List_of_cognitive_biases</li></ul>
</li>
<li>Implement techniques from microscopy for scanning at a human level for computational portraiture?&nbsp;</li><ul style="list-style: none;"><li>3D from EDF via focus stacking – <a href="http://bigwww.epfl.ch/demo/edf/"></a>http://bigwww.epfl.ch/demo/edf/</li></ul>
</li>
<li>Make &rsquo;found data&rsquo; renderings using my collection of publicly available SLAM datasets.&nbsp;</li></ul>

<p><b>Notes &amp; Quotes:</b></p><ul style="list-style: none;"><li>[Experimental photographers] are in fact consciously attempting to create unpredictable information, i.e. to release themselves from the camera, and to place within the image something that is not in its program. They know they are playing against the camera. Yet even they are not conscious of the consequence of their practice: they are not aware that they are attempting to address the question of freedom in the context of apparatus in general.</li>
<li>VILÉM FLUSSER from <i>Towards a Philosophy of Photography</i></li></ul>

<p><b>Resources</b></p><ul style="list-style: none;"><li><b>Text</b></li>
<li>PIXEL PERFECT | The scientist behind the digital cloning of actors.</li>
<li><a href="http://www.newyorker.com/reporting/2014/04/28/140428fa_fact_talbot"></a>http://www.newyorker.com/reporting/2014/04/28/140428fa_fact_talbot</li></ul>

<ul style="list-style: none;"><li>Program Or Be Programmed<ul style="list-style: none;"><li>Is this paradigm useful as applied to camera/vision tech?&nbsp;</li></ul>
</ul>

<ul style="list-style: none;"><li><b>Misc</b></li>
<li>Camera exploitation:</li></ul>
<p>*</p><p></p><ul style="list-style: none;"><li>Magic Lantern Scripting:</li>
<li><a href="http://www.magiclantern.fm/forum/index.php?board=5.0"></a>http://www.magiclantern.fm/forum/index.php?board=5.0</li></ul>
<p>*</p><p></p><ul style="list-style: none;"><li>Method for extraction and presentation of image content from captured wireless traffic<ul style="list-style: none;"><li><a href="http://julianoliver.com/output/log_2014-04-23_21-12"></a><a href='http://julianoliver.com/output/log_2014-04-23_21-12'/>http://julianoliver.com/output/log_2014-04-23_21-12</a><ul style="list-style: none;"><li>Tried to implement it (unsuccessfully)&nbsp;</li></ul style="list-style: none;">
</li></ul style="list-style: none;">
</li>
<li>Eyefi hacking [ attn: <a href='/ep/profile/uABG7ngMwBe'/>Jonathan Dahan</a> ]&nbsp;<ul style="list-style: none;"><li><a href="http://magiclantern.wikia.com/wiki/Eye-Fi"></a>http://magiclantern.wikia.com/wiki/Eye-Fi</li>
<li><a href="http://dave-hansen.blogspot.com/2007/12/new-eyefi-card.html"></a>http://dave-hansen.blogspot.com/2007/12/new-eyefi-card.html</li>
<li><a href="http://hackaday.com/?s=eyefi"></a>http://hackaday.com/?s=eyefi</li></ul>
</ul>
<p><b>Diary</b></p><ul style="list-style: none;"><li>20140424<ul style="list-style: none;"><li>We did some work with the terminal &amp; interacting with existing APIs using Processing.&nbsp;</li><ul class="task"><li>Make a repository for some of this code.&nbsp;</li>
<li>Learn how to scrape down images off arbitrary pages.&nbsp;&nbsp;</li></ul>
</ul>
</ul>

<ul style="list-style: none;"><li>I worked a bit with <a href='/ep/profile/AFmNPnnCbtQ'/>scott</a> trying to make sense of some ofxAddons with the intention of learning a bit about 3D &amp; eventually making a demo to visualize environmental usage data at a &rsquo;human scale.&rsquo; I found it to be <i>very </i>useful to work with someone else who is at around the same level of understanding to make sense of code. We found that just using xcode and getting the code to run accounted for ~75% of the time spent. But it was very exciting to start seeing things in 3D. Scott is an architect &amp; I think spatially so I think we both found it useful to start drawing in 3D to understand principles.&nbsp;</li>
<li>&nbsp;</li>
<li><i>20140425</i></li>
<li>I&rsquo;m wondering about the best way to get something useful &amp; lasting out of this incredibly brief period. Overnight I had some &rsquo;buyers remorse&rsquo; in regards to the amount of time I&rsquo;ve put aside for this and felt a deep concern about making the experience useful. I&rsquo;m well aware that the responsibility lays with me so I&rsquo;m working out ways to refine my experience here to get what I need. I think that that will come by reductively limiting my cognitive input – I&rsquo;m finding that doing a sort of &rsquo;drive by&rsquo; on a lot of these practices &amp; techniques is incredibly beneficial in that I&rsquo;m able to sort out what I <i>don&rsquo;t</i> want to be working on.&nbsp;</li></ul>

<ul style="list-style: none;"><li>I have an existing community, references, resources etc. and I&rsquo;m finding that in my work it&rsquo;s becoming increasingly important to limit and dig deep rather than skimming new materials. To that end I think it will be important to focus on two areas: refining my ideas in relation to my existing work &amp; practice &amp; use the presence of expertise to jump into projects that are outside my current range of expertise.&nbsp;</li>
<li><br/></li>
<li>The efforts I&rsquo;m starting to focus on in order to make this practical for me are the following:&nbsp;</li><ul><li>Shutting myself into a room to read &amp; diagram about my topics of interest and the reasons for my practice.&nbsp;<ul><li>Mapping out my references, bibliography and arguments.</li></ul>
</ul>
</ul>
<ul style="list-style: none;"><li><br/></li><ul><li>Implementing some of the techniques that I&rsquo;ve been wanting to work on as learning foils.<ul><li>A camera that returns the top google image (tinEye?) result in place of the image you took.&nbsp;</li>
<li>A &rsquo;dataviz&rsquo; project re: materials intensity.&nbsp;<ul><li>Creating a &rsquo;life-sized&rsquo; experience of materials intensity.&nbsp;</li></ul>
</li>
<li>Teaching methods for computer vision techniques.&nbsp;<ul><li>SfM/photogrammetry/optical flow with string? etc.</li></ul>
</li>
<li>EDF/Defocus-based scanning&nbsp;<ul><li>Using magic lantern focus stepping + imageJ to make depth maps.&nbsp;</li></ul>
</li>
<li>Visualizing SLAM datasets for &rsquo;found model&rsquo; fly-throughs of robotics labs etc.&nbsp;</li>
<li>Use a GL interceptor to get data out of google earth/OS X Maps apps.&nbsp;<ul><li>Reconstruct the results if poss?</li></ul>
</ul>
</ul>
<ul style="list-style: none;"><li><br/></li></ul>
</ul>

</body>
</html>
